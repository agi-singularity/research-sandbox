{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00fbcbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from simhash import Simhash, SimhashIndex\n",
    "from itertools import combinations_with_replacement\n",
    "from collections import defaultdict\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy.sparse.csgraph import connected_components\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f9a5e3",
   "metadata": {},
   "source": [
    "# Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b4b8bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ads = pd.read_csv('kaggle_text_classified_ads.csv').reset_index().iloc[:1000]\n",
    "data_ads = data_ads[['index', 'value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "053c0f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(s):\n",
    "    \"\"\"\n",
    "    Returns list of substrings of a given width.  Example: 'how are' -> ['how', 'owa', 'war', 'are']\n",
    "    \"\"\"\n",
    "    width = 3\n",
    "    s = s.lower()\n",
    "    s = re.sub(r'[^\\w]+', '', s)\n",
    "    return [s[i:i + width] for i in range(max(len(s) - width + 1, 1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba78fa35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5570291454580194887"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the hash value\n",
    "Simhash(get_features('How are you? I am fine. Thanks.')).value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf2582f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate hash distance\n",
    "Simhash(get_features('How are you? We are fine. Thanks.')).distance(Simhash(get_features('How are you? I am fine. Thanks.')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99173391",
   "metadata": {},
   "source": [
    "# Hash the Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4a053772",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ads_dict = data_ads['value'].to_dict()\n",
    "\n",
    "# hash the documents\n",
    "data_ads_objs = [(str(k), Simhash(get_features(v))) for k, v in data_ads_dict.items()]\n",
    "\n",
    "# create an index for efficient searching\n",
    "distance_threshold = 3  # hashes > this value will not be considered similar\n",
    "index = SimhashIndex(data_ads_objs, k=distance_threshold)\n",
    "\n",
    "assert(len(data_ads_objs) == len(data_ads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "06d6fff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? Our innovative occupational therapy clinical programs will challenge new and experienced Occupational Therapists. We have state:of:the:art ACP equipment, modality based programs, well equipped gyms and much more. Our Rehab Directors are experienced, organized, manage schedules well and lead our therapy teams in the ethical care of our residents. If you ve always wanted to work for a company that supports your occupational therapy career development or can help you maintain a work/life balance, you owe it to yourself to find out more about AFFIRMA Rehabilitation.\\r\\n \\r\\nAFFIRMA Rehabilitation is changing the way you look at geriatric rehabilitation. With our Homeward Bound Programs, AFFIRMA Rehabilitation facilities are now returning over 75 of their residents to home or community level living. Our interdisciplinary team of Physical, Occupational and Speech Therapists use a collaborative approach to finding the right plan of care of each patient. Patient focused care is priority 1.\\r\\n \\r\\nAs a full:time Occupational Therapist at AFFIRMA Rehabilitation, you ll enjoy comprehensive benefits and employee programs:\\r\\n Excellent pay, 23 days PTO\\r\\n Comprehensive benefits, 401k, life insurance\\r\\n In:house CEUs\\r\\n New grad occupational therapy mentorship and leadership training\\r\\n OT License renewal reimbursement\\r\\n Point of service documentation with iPad technology\\r\\n Paid professional liability insurance\\r\\n Flexible scheduling, nationwide locations and more\\r\\n \\r\\nTake pride in our reputation for giving outstanding patient care.\\r\\n \\r\\n Qualifications \\r\\n \\r\\nMaster s degree in Occupational Therapy (new grad OTs are welcome).\\r\\nActive Occupational Therapy license.\\r\\nAbility to practice occupational therapy unencumbered within state and federal guidelines.\\r\\nPassion for aiding and working with the elderly.\\r\\n \\r\\nPreferred, but not required:\\r\\nExperience working with elderly patients.\\r\\n \\r\\nEssential qualities and attributes:\\r\\nStrong critical thinking and problem solving skills.\\r\\nExcellent written and verbal communication skills.\\r\\nTeam attitude.\\r\\nFlexibility.\\r\\n \\r\\nKeywords: occupational therapist, occupational therapy, OT\\r\\n\\r\\nAssociated topics: cht, certified occupational therapy assistant, cota, ffs, occupational, occupational therapist, occupational therapist ot, therapist, therapist ot']\n"
     ]
    }
   ],
   "source": [
    "# example of finding similar texts for 1 provided text\n",
    "similar_docs = index.get_near_dups(data_ads_objs[0][1])\n",
    "similar_docs_text = [data_ads_dict[int(k)] for k in similar_docs]\n",
    "print(similar_docs_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "25664e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1710"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(index.bucket.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75369b3c",
   "metadata": {},
   "source": [
    "# Assign Document Clusters based on Hash Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "160f66ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine how many clusters there are and which docs belong to each cluster\n",
    "clusters = {}\n",
    "cluster_id = 0\n",
    "for simhash_key, hashes in index.bucket.items():\n",
    "    similar_doc_ids = [int(hash_details.split(\",\")[1]) for hash_details in hashes]\n",
    "    clusters[cluster_id] = set(similar_doc_ids)\n",
    "    cluster_id += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dc088a",
   "metadata": {},
   "source": [
    "Clusters seems like it should contain the cluster assignments for each document, but there are documents appearing in multiple clusters.  To de-duplicate, I will form an adjancency matrix and extract connected components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "17d900ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "798731 1000 (8954, 8954) 798731\n"
     ]
    }
   ],
   "source": [
    "print(len(edges), len(data_ads), matrix_shape, len(rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "71966a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of tuples representing the edges in a graph\n",
    "edges = set([(x, y) for c in clusters.values() for x, y in combinations_with_replacement(c, 2)])\n",
    "\n",
    "# create an adjency matrix from the edge list\n",
    "matrix_shape = (len(data_ads), len(data_ads))  # will be a square adjacency matrix\n",
    "rows, cols = zip(*edges)\n",
    "sparse_mat = coo_matrix((np.ones(len(edges)), (rows, cols)), shape=matrix_shape)\n",
    "\n",
    "# get the cluster for each document\n",
    "nbr_clusters, cluster = connected_components(sparse_mat)\n",
    "data_ads['cluster'] = cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e1a2055b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>value</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Be your own boss working under a Strong Brand ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Be your own boss working under a Strong Brand ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Be your own boss working under a Strong Brand ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Be your own boss working under a Strong Brand ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Be your own boss working under a Strong Brand ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>114</td>\n",
       "      <td>Be your own boss working under a Strong Brand ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>115</td>\n",
       "      <td>Be your own boss working under a Strong Brand ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>116</td>\n",
       "      <td>Be your own boss working under a Strong Brand ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>117</td>\n",
       "      <td>Be your own boss working under a Strong Brand ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>118</td>\n",
       "      <td>Be your own boss working under a Strong Brand ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                              value  cluster\n",
       "3        3  Be your own boss working under a Strong Brand ...        3\n",
       "4        4  Be your own boss working under a Strong Brand ...        3\n",
       "5        5  Be your own boss working under a Strong Brand ...        3\n",
       "6        6  Be your own boss working under a Strong Brand ...        3\n",
       "7        7  Be your own boss working under a Strong Brand ...        3\n",
       "..     ...                                                ...      ...\n",
       "114    114  Be your own boss working under a Strong Brand ...        3\n",
       "115    115  Be your own boss working under a Strong Brand ...        3\n",
       "116    116  Be your own boss working under a Strong Brand ...        3\n",
       "117    117  Be your own boss working under a Strong Brand ...        3\n",
       "118    118  Be your own boss working under a Strong Brand ...        3\n",
       "\n",
       "[109 rows x 3 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inspect a cluster\n",
    "data_ads[data_ads['cluster']==3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2402798a",
   "metadata": {},
   "source": [
    "# Try Adding New Docs\n",
    "\n",
    "New docs can be added to the index without having to rebuild it from scratch.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "5332a677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1000', <simhash.Simhash object at 0x7fe28f038fd0>)\n",
      "('1001', <simhash.Simhash object at 0x7fe2aef98c40>)\n",
      "('1002', <simhash.Simhash object at 0x7fe29044d250>)\n",
      "('1003', <simhash.Simhash object at 0x7fe2e58184c0>)\n",
      "('1004', <simhash.Simhash object at 0x7fe28f04b6a0>)\n",
      "('1005', <simhash.Simhash object at 0x7fe28f04b670>)\n",
      "('1006', <simhash.Simhash object at 0x7fe28f04bd30>)\n",
      "('1007', <simhash.Simhash object at 0x7fe28f04b580>)\n",
      "('1008', <simhash.Simhash object at 0x7fe28f04ba00>)\n",
      "('1009', <simhash.Simhash object at 0x7fe28f04baf0>)\n"
     ]
    }
   ],
   "source": [
    "data_ads_new = pd.read_csv('kaggle_text_classified_ads.csv').reset_index().iloc[1000:1010]\n",
    "data_ads_new = data_ads_new[['index', 'value']]\n",
    "\n",
    "data_ads_new_dict = data_ads_new['value'].to_dict()\n",
    "\n",
    "# hash the documents\n",
    "data_ads_new_objs = [(str(k), Simhash(get_features(v))) for k, v in data_ads_new_dict.items()]\n",
    "assert(len(data_ads_new_objs) == len(data_ads_new))\n",
    "\n",
    "# update the index\n",
    "for obj in data_ads_new_objs:\n",
    "    index.add(*obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "eb5bc769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine how many clusters there are and which docs belong to each cluster\n",
    "clusters = {}\n",
    "cluster_id = 0\n",
    "for simhash_key, hashes in index.bucket.items():\n",
    "    similar_doc_ids = [int(hash_details.split(\",\")[1]) for hash_details in hashes]\n",
    "    clusters[cluster_id] = set(similar_doc_ids)\n",
    "    cluster_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ec241811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of tuples representing the edges in a graph\n",
    "edges = set([(x, y) for c in clusters.values() for x, y in combinations_with_replacement(c, 2)])\n",
    "\n",
    "# create an adjency matrix from the edge list\n",
    "matrix_shape = (len(data_ads)+len(data_ads_new), len(data_ads)+len(data_ads_new))  # will be a square adjacency matrix\n",
    "rows, cols = zip(*edges)\n",
    "sparse_mat = coo_matrix((np.ones(len(edges)), (rows, cols)), shape=matrix_shape)\n",
    "\n",
    "# get the cluster for each document\n",
    "nbr_clusters, cluster = connected_components(sparse_mat)\n",
    "data_ads_new['cluster'] = cluster[-len(data_ads_new):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d8dbb4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>value</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>1000</td>\n",
       "      <td>Job Description:/h3:\\r\\n\\r\\nExamples of Import...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>1001</td>\n",
       "      <td>Branch Location: San Jose, CA \\r\\n\\r\\n Carpet ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>1002</td>\n",
       "      <td>Registered Nurses Only \\r\\n Seasonal Nationwid...</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>1003</td>\n",
       "      <td>Branch Location: San Jose, CA \\r\\n\\r\\n Carpet ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>1004</td>\n",
       "      <td>Calling All Production Workers\\r\\n\\r\\nJob Desc...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                              value  cluster\n",
       "1000   1000  Job Description:/h3:\\r\\n\\r\\nExamples of Import...        5\n",
       "1001   1001  Branch Location: San Jose, CA \\r\\n\\r\\n Carpet ...        5\n",
       "1002   1002  Registered Nurses Only \\r\\n Seasonal Nationwid...      108\n",
       "1003   1003  Branch Location: San Jose, CA \\r\\n\\r\\n Carpet ...        5\n",
       "1004   1004  Calling All Production Workers\\r\\n\\r\\nJob Desc...        5"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ads_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df84fb4",
   "metadata": {},
   "source": [
    "# Evaluate on Public Text Similarity Datasets\n",
    "\n",
    "Datasets used:\n",
    "1. Google PAWS for paraphrased sentence pairs, https://huggingface.co/datasets/paws\n",
    "2. Kaggle Text Classified Ads, https://www.kaggle.com/overflow012/playing-with-ads\n",
    "\n",
    "The text classified ads have duplicates but they are not labeled, so I will do a pairwise comparison of a selection of rows to identify exact, verbatim duplicates.  This will test Simhash's ability to find perfect matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "efe05f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset paws (/Users/nicholaslincoln/.cache/huggingface/datasets/paws/labeled_final/1.1.0/8d567c6472623f42bd2cc635cad06932d0f0cd2f897db56013c1180f4317d338)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['id', 'sentence1', 'sentence2', 'label'],\n",
      "    num_rows: 49401\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "paws = load_dataset(\"paws\", \"labeled_final\", split=\"train\")\n",
    "print(paws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "15648ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the sentences will have to be combined for hashing, but keep the index so they can be split back out\n",
    "split_idx = len(paws)\n",
    "paws_all_sents = paws['sentence1'] + paws['sentence2']\n",
    "paws_dict = {idx: sent for idx, sent in enumerate(paws_all_sents)}\n",
    "\n",
    "# hash the documents\n",
    "paws_objs = [(str(k), Simhash(get_features(v))) for k, v in paws_dict.items()]\n",
    "\n",
    "# create an index for efficient searching\n",
    "distance_threshold = 3  # hashes > this value will not be considered similar, value must be an integer\n",
    "index = SimhashIndex(paws_objs, k=distance_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "75576019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine how many clusters there are and which docs belong to each cluster\n",
    "clusters = {}\n",
    "cluster_id = 0\n",
    "for simhash_key, hashes in index.bucket.items():\n",
    "    similar_doc_ids = [int(hash_details.split(\",\")[1]) for hash_details in hashes]\n",
    "    clusters[cluster_id] = set(similar_doc_ids)\n",
    "    cluster_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "b790f1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of tuples representing the edges in a graph\n",
    "edges = set([(x, y) for c in clusters.values() for x, y in combinations_with_replacement(c, 2)])\n",
    "\n",
    "# create an adjency matrix from the edge list\n",
    "matrix_shape = (len(paws_dict), len(paws_dict))  # will be a square adjacency matrix\n",
    "rows, cols = zip(*edges)\n",
    "sparse_mat = coo_matrix((np.ones(len(edges)), (rows, cols)), shape=matrix_shape)\n",
    "\n",
    "# get the cluster for each document\n",
    "nbr_clusters, cluster = connected_components(sparse_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "60d5844f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split eval data back into 2 columns, add cluster, add label\n",
    "eval_df = pd.DataFrame({\n",
    "    'sent1': paws['sentence1'],\n",
    "    'sent2': paws['sentence2'],\n",
    "    'label': paws['label'],\n",
    "    'cluster1': cluster[:split_idx],\n",
    "    'cluster2': cluster[split_idx:]\n",
    "})\n",
    "eval_df['simhash_predicted_similar'] = np.where(eval_df.cluster1 == eval_df.cluster2, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "782ec55c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simhash Evaluation on Google PAWS:\n",
      " accuracy: 0.449647\n",
      " precision: 0.443090\n",
      " recall: 0.955701\n",
      " f1: 0.605468\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Simhash Evaluation on Google PAWS:\\n\",\n",
    "    f\"accuracy: {accuracy_score(eval_df.label, eval_df.simhash_predicted_similar):2f}\\n\",\n",
    "    f\"precision: {precision_score(eval_df.label, eval_df.simhash_predicted_similar):2f}\\n\",\n",
    "    f\"recall: {recall_score(eval_df.label, eval_df.simhash_predicted_similar):2f}\\n\",\n",
    "    f\"f1: {f1_score(eval_df.label, eval_df.simhash_predicted_similar):2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "7fb8923a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9530778729175523"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.simhash_predicted_similar.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3b7c6c",
   "metadata": {},
   "source": [
    "So it misses very few texts that are similar, but it has a lot of false positives.  I found that playing with the distance threshold, k, had a big impact, but since it must be an integer, setting it to 2 was too low (it missed everything) and 3 is almost too high (nearly everything is considered similar).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "93e5fba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent1</th>\n",
       "      <th>sent2</th>\n",
       "      <th>label</th>\n",
       "      <th>cluster1</th>\n",
       "      <th>cluster2</th>\n",
       "      <th>simhash_predicted_similar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In Paris , in October 1560 , he secretly met t...</td>\n",
       "      <td>In October 1560 , he secretly met with the Eng...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The NBA season of 1975 -- 76 was the 30th seas...</td>\n",
       "      <td>The 1975 -- 76 season of the National Basketba...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>There are also specific discussions , public p...</td>\n",
       "      <td>There are also public discussions , profile sp...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When comparable rates of flow can be maintaine...</td>\n",
       "      <td>The results are high when comparable flow rate...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It is the seat of Zerendi District in Akmola R...</td>\n",
       "      <td>It is the seat of the district of Zerendi in A...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>William Henry Henry Harman was born on 17 Febr...</td>\n",
       "      <td>William Henry Harman was born in Waynesboro , ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bullion Express - concept is being introduced ...</td>\n",
       "      <td>2011-DGSE Bullion Express concept is introduce...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>With a discrete amount of probabilities Formul...</td>\n",
       "      <td>Given a discrete set of probabilities formula ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Soviet Union maintained an embassy in Oslo...</td>\n",
       "      <td>The Soviet Union maintained an embassy in Mosc...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Vocabulary even went to Brazil through leaving...</td>\n",
       "      <td>Vocabulary even went to Brazil by leaving Maca...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kabir Suman recorded several albums under the ...</td>\n",
       "      <td>Suman Chatterjee , recorded a number of albums...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>He was a scholar in Metaphysical Literature , ...</td>\n",
       "      <td>He was a scholar in metaphysical literature , ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The city sits at the confluence of the Snake R...</td>\n",
       "      <td>The city lies at the confluence of the Snake R...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>He has been trained by his grandfather , Nick ...</td>\n",
       "      <td>He has been trained by his grandfather , Geoff...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The Austrian school assumes that the subjectiv...</td>\n",
       "      <td>The Austrian school assumes that the subjectiv...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Werder 's forces invested Belfort and reached ...</td>\n",
       "      <td>Werder 's troops invested Belfort and reached ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The kBox facilitates both isometric and concen...</td>\n",
       "      <td>The kBox facilitates eccentric as well as conc...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>664</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>The first five weapons were delivered in the f...</td>\n",
       "      <td>The first five weapons were delivered in the f...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Elizabeth II was an ancestor of Queens Edzard ...</td>\n",
       "      <td>Edzard II was an ancestor of the Queens Elizab...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The friendship between him and Duncan ended at...</td>\n",
       "      <td>The friendship between him and Duncan ended in...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Pluto was classified as the planet when the Gr...</td>\n",
       "      <td>Note : Pluto was classified as a planet when t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>For their performances in the game , quarterba...</td>\n",
       "      <td>Quarterback P. J. Williams and Defensive Back ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Shaffer Creek is a tributary of the Raystown B...</td>\n",
       "      <td>Shaffer Creek is an tributary of Brush Creek (...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Kevin Spacey ( Henry Drummond ) and David Trou...</td>\n",
       "      <td>Kevin Spacey ( Henry Drummond ) and David Trou...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Briggs later met Briggs at the 1967 Monterey P...</td>\n",
       "      <td>Briggs met Briggs later at the Monterey Pop Fe...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sent1  \\\n",
       "0   In Paris , in October 1560 , he secretly met t...   \n",
       "1   The NBA season of 1975 -- 76 was the 30th seas...   \n",
       "2   There are also specific discussions , public p...   \n",
       "3   When comparable rates of flow can be maintaine...   \n",
       "4   It is the seat of Zerendi District in Akmola R...   \n",
       "5   William Henry Henry Harman was born on 17 Febr...   \n",
       "6   Bullion Express - concept is being introduced ...   \n",
       "7   With a discrete amount of probabilities Formul...   \n",
       "8   The Soviet Union maintained an embassy in Oslo...   \n",
       "9   Vocabulary even went to Brazil through leaving...   \n",
       "10  Kabir Suman recorded several albums under the ...   \n",
       "11  He was a scholar in Metaphysical Literature , ...   \n",
       "12  The city sits at the confluence of the Snake R...   \n",
       "13  He has been trained by his grandfather , Nick ...   \n",
       "14  The Austrian school assumes that the subjectiv...   \n",
       "15  Werder 's forces invested Belfort and reached ...   \n",
       "16  The kBox facilitates both isometric and concen...   \n",
       "17  The first five weapons were delivered in the f...   \n",
       "18  Elizabeth II was an ancestor of Queens Edzard ...   \n",
       "19  The friendship between him and Duncan ended at...   \n",
       "20  Pluto was classified as the planet when the Gr...   \n",
       "21  For their performances in the game , quarterba...   \n",
       "22  Shaffer Creek is a tributary of the Raystown B...   \n",
       "23  Kevin Spacey ( Henry Drummond ) and David Trou...   \n",
       "24  Briggs later met Briggs at the 1967 Monterey P...   \n",
       "\n",
       "                                                sent2  label  cluster1  \\\n",
       "0   In October 1560 , he secretly met with the Eng...      0         0   \n",
       "1   The 1975 -- 76 season of the National Basketba...      1         0   \n",
       "2   There are also public discussions , profile sp...      0         0   \n",
       "3   The results are high when comparable flow rate...      1         0   \n",
       "4   It is the seat of the district of Zerendi in A...      1         0   \n",
       "5   William Henry Harman was born in Waynesboro , ...      1         0   \n",
       "6   2011-DGSE Bullion Express concept is introduce...      0         0   \n",
       "7   Given a discrete set of probabilities formula ...      1         0   \n",
       "8   The Soviet Union maintained an embassy in Mosc...      0         0   \n",
       "9   Vocabulary even went to Brazil by leaving Maca...      0         0   \n",
       "10  Suman Chatterjee , recorded a number of albums...      0         0   \n",
       "11  He was a scholar in metaphysical literature , ...      1         0   \n",
       "12  The city lies at the confluence of the Snake R...      1         0   \n",
       "13  He has been trained by his grandfather , Geoff...      0         0   \n",
       "14  The Austrian school assumes that the subjectiv...      0         0   \n",
       "15  Werder 's troops invested Belfort and reached ...      1         0   \n",
       "16  The kBox facilitates eccentric as well as conc...      0         1   \n",
       "17  The first five weapons were delivered in the f...      1         0   \n",
       "18  Edzard II was an ancestor of the Queens Elizab...      0         0   \n",
       "19  The friendship between him and Duncan ended in...      1         0   \n",
       "20  Note : Pluto was classified as a planet when t...      0         0   \n",
       "21  Quarterback P. J. Williams and Defensive Back ...      0         0   \n",
       "22  Shaffer Creek is an tributary of Brush Creek (...      1         0   \n",
       "23  Kevin Spacey ( Henry Drummond ) and David Trou...      0         2   \n",
       "24  Briggs met Briggs later at the Monterey Pop Fe...      1         0   \n",
       "\n",
       "    cluster2  simhash_predicted_similar  \n",
       "0          0                          1  \n",
       "1          0                          1  \n",
       "2          0                          1  \n",
       "3          0                          1  \n",
       "4          0                          1  \n",
       "5          0                          1  \n",
       "6          0                          1  \n",
       "7          0                          1  \n",
       "8          0                          1  \n",
       "9          0                          1  \n",
       "10         0                          1  \n",
       "11         0                          1  \n",
       "12         0                          1  \n",
       "13         0                          1  \n",
       "14       109                          0  \n",
       "15         0                          1  \n",
       "16       664                          0  \n",
       "17         0                          1  \n",
       "18         0                          1  \n",
       "19         0                          1  \n",
       "20         0                          1  \n",
       "21         0                          1  \n",
       "22         0                          1  \n",
       "23         0                          0  \n",
       "24         0                          1  "
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feea0aa6",
   "metadata": {},
   "source": [
    "### Eval on Perfect Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68277e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shrink dataset to make it more manageable\n",
    "data_ads_sub = data_ads.iloc[:50]\n",
    "\n",
    "# create labels for verbatim similarity for text classified ads\n",
    "comparison_dict = {}\n",
    "comparison_dict_index = 0\n",
    "data_ads_docs = data_ads_sub.value.tolist()\n",
    "for doc_1 in data_ads_docs:\n",
    "    for doc_2 in data_ads_docs:\n",
    "        if doc_1 == doc_2:\n",
    "            comparison_dict[comparison_dict_index] = (doc_1, doc_2, 1)\n",
    "        else:\n",
    "            comparison_dict[comparison_dict_index] = (doc_1, doc_2, 0)\n",
    "        comparison_dict_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eac2d692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc1</th>\n",
       "      <th>doc2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...</td>\n",
       "      <td>Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...</td>\n",
       "      <td>Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...</td>\n",
       "      <td>Overview:\\r\\n\\r\\nUnder general supervision by ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...</td>\n",
       "      <td>Be your own boss working under a Strong Brand ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...</td>\n",
       "      <td>Be your own boss working under a Strong Brand ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                doc1  \\\n",
       "0  Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...   \n",
       "1  Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...   \n",
       "2  Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...   \n",
       "3  Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...   \n",
       "4  Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...   \n",
       "\n",
       "                                                doc2  label  \n",
       "0  Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...      1  \n",
       "1  Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...      0  \n",
       "2  Overview:\\r\\n\\r\\nUnder general supervision by ...      0  \n",
       "3  Be your own boss working under a Strong Brand ...      0  \n",
       "4  Be your own boss working under a Strong Brand ...      0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = pd.DataFrame.from_dict(comparison_dict, orient=\"index\", columns=[\"doc1\", \"doc2\", \"label\"])\n",
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ffa07f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the sentences will have to be combined for hashing, but keep the index so they can be split back out\n",
    "split_idx = len(eval_df)\n",
    "eval_df_all_sents = eval_df['doc1'].tolist() + eval_df['doc2'].tolist()\n",
    "eval_df_dict = {idx: sent for idx, sent in enumerate(eval_df_all_sents)}\n",
    "\n",
    "# hash the documents\n",
    "eval_df_objs = [(str(k), Simhash(get_features(v))) for k, v in eval_df_dict.items()]\n",
    "\n",
    "# create an index for efficient searching\n",
    "distance_threshold = 3  # hashes > this value will not be considered similar, value must be an integer\n",
    "index = SimhashIndex(eval_df_objs, k=distance_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e46fa3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine how many clusters there are and which docs belong to each cluster\n",
    "clusters = {}\n",
    "cluster_id = 0\n",
    "for simhash_key, hashes in index.bucket.items():\n",
    "    similar_doc_ids = [int(hash_details.split(\",\")[1]) for hash_details in hashes]\n",
    "    clusters[cluster_id] = set(similar_doc_ids)\n",
    "    cluster_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ef424620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of tuples representing the edges in a graph\n",
    "edges = set([(x, y) for c in clusters.values() for x, y in combinations_with_replacement(c, 2)])\n",
    "\n",
    "# create an adjency matrix from the edge list\n",
    "matrix_shape = (len(eval_df_dict), len(eval_df_dict))  # will be a square adjacency matrix\n",
    "rows, cols = zip(*edges)\n",
    "sparse_mat = coo_matrix((np.ones(len(edges)), (rows, cols)), shape=matrix_shape)\n",
    "\n",
    "# get the cluster for each document\n",
    "nbr_clusters, cluster = connected_components(sparse_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f937843e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split eval data back into 2 columns, add cluster, add label\n",
    "eval_df['cluster1'] = cluster[:split_idx]\n",
    "eval_df['cluster2'] = cluster[split_idx:]\n",
    "eval_df['simhash_predicted_similar'] = np.where(eval_df.cluster1 == eval_df.cluster2, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "27920a0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simhash Evaluation on Google PAWS:\n",
      " accuracy: 1.000000\n",
      " precision: 1.000000\n",
      " recall: 1.000000\n",
      " f1: 1.000000\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Simhash Evaluation on Google PAWS:\\n\",\n",
    "    f\"accuracy: {accuracy_score(eval_df.label, eval_df.simhash_predicted_similar):2f}\\n\",\n",
    "    f\"precision: {precision_score(eval_df.label, eval_df.simhash_predicted_similar):2f}\\n\",\n",
    "    f\"recall: {recall_score(eval_df.label, eval_df.simhash_predicted_similar):2f}\\n\",\n",
    "    f\"f1: {f1_score(eval_df.label, eval_df.simhash_predicted_similar):2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "29b2ae5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc1</th>\n",
       "      <th>doc2</th>\n",
       "      <th>label</th>\n",
       "      <th>cluster1</th>\n",
       "      <th>cluster2</th>\n",
       "      <th>simhash_predicted_similar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...</td>\n",
       "      <td>Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...</td>\n",
       "      <td>Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...</td>\n",
       "      <td>Overview:\\r\\n\\r\\nUnder general supervision by ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...</td>\n",
       "      <td>Be your own boss working under a Strong Brand ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...</td>\n",
       "      <td>Be your own boss working under a Strong Brand ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...</td>\n",
       "      <td>Be your own boss working under a Strong Brand ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...</td>\n",
       "      <td>Be your own boss working under a Strong Brand ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...</td>\n",
       "      <td>Be your own boss working under a Strong Brand ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...</td>\n",
       "      <td>Be your own boss working under a Strong Brand ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...</td>\n",
       "      <td>Be your own boss working under a Strong Brand ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...</td>\n",
       "      <td>Be your own boss working under a Strong Brand ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...</td>\n",
       "      <td>Be your own boss working under a Strong Brand ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...</td>\n",
       "      <td>Be your own boss working under a Strong Brand ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...</td>\n",
       "      <td>Be your own boss working under a Strong Brand ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...</td>\n",
       "      <td>Be your own boss working under a Strong Brand ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...</td>\n",
       "      <td>A California group is currently seeking a locu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...</td>\n",
       "      <td>Be your own boss working under a Strong Brand ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...</td>\n",
       "      <td>Be your own boss working under a Strong Brand ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...</td>\n",
       "      <td>Be your own boss working under a Strong Brand ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...</td>\n",
       "      <td>Be your own boss working under a Strong Brand ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...</td>\n",
       "      <td>Be your own boss working under a Strong Brand ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...</td>\n",
       "      <td>Be your own boss working under a Strong Brand ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...</td>\n",
       "      <td>Be your own boss working under a Strong Brand ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...</td>\n",
       "      <td>Be your own boss working under a Strong Brand ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...</td>\n",
       "      <td>Be your own boss working under a Strong Brand ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 doc1  \\\n",
       "0   Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...   \n",
       "1   Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...   \n",
       "2   Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...   \n",
       "3   Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...   \n",
       "4   Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...   \n",
       "5   Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...   \n",
       "6   Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...   \n",
       "7   Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...   \n",
       "8   Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...   \n",
       "9   Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...   \n",
       "10  Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...   \n",
       "11  Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...   \n",
       "12  Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...   \n",
       "13  Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...   \n",
       "14  Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...   \n",
       "15  Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...   \n",
       "16  Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...   \n",
       "17  Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...   \n",
       "18  Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...   \n",
       "19  Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...   \n",
       "20  Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...   \n",
       "21  Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...   \n",
       "22  Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...   \n",
       "23  Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...   \n",
       "24  Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...   \n",
       "\n",
       "                                                 doc2  label  cluster1  \\\n",
       "0   Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...      1         0   \n",
       "1   Overview \\r\\n \\r\\nWhy AFFIRMA Rehabilitation? ...      0         0   \n",
       "2   Overview:\\r\\n\\r\\nUnder general supervision by ...      0         0   \n",
       "3   Be your own boss working under a Strong Brand ...      0         0   \n",
       "4   Be your own boss working under a Strong Brand ...      0         0   \n",
       "5   Be your own boss working under a Strong Brand ...      0         0   \n",
       "6   Be your own boss working under a Strong Brand ...      0         0   \n",
       "7   Be your own boss working under a Strong Brand ...      0         0   \n",
       "8   Be your own boss working under a Strong Brand ...      0         0   \n",
       "9   Be your own boss working under a Strong Brand ...      0         0   \n",
       "10  Be your own boss working under a Strong Brand ...      0         0   \n",
       "11  Be your own boss working under a Strong Brand ...      0         0   \n",
       "12  Be your own boss working under a Strong Brand ...      0         0   \n",
       "13  Be your own boss working under a Strong Brand ...      0         0   \n",
       "14  Be your own boss working under a Strong Brand ...      0         0   \n",
       "15  A California group is currently seeking a locu...      0         0   \n",
       "16  Be your own boss working under a Strong Brand ...      0         0   \n",
       "17  Be your own boss working under a Strong Brand ...      0         0   \n",
       "18  Be your own boss working under a Strong Brand ...      0         0   \n",
       "19  Be your own boss working under a Strong Brand ...      0         0   \n",
       "20  Be your own boss working under a Strong Brand ...      0         0   \n",
       "21  Be your own boss working under a Strong Brand ...      0         0   \n",
       "22  Be your own boss working under a Strong Brand ...      0         0   \n",
       "23  Be your own boss working under a Strong Brand ...      0         0   \n",
       "24  Be your own boss working under a Strong Brand ...      0         0   \n",
       "\n",
       "    cluster2  simhash_predicted_similar  \n",
       "0          0                          1  \n",
       "1          1                          0  \n",
       "2          2                          0  \n",
       "3          3                          0  \n",
       "4          3                          0  \n",
       "5          3                          0  \n",
       "6          3                          0  \n",
       "7          3                          0  \n",
       "8          3                          0  \n",
       "9          3                          0  \n",
       "10         3                          0  \n",
       "11         3                          0  \n",
       "12         3                          0  \n",
       "13         3                          0  \n",
       "14         3                          0  \n",
       "15         4                          0  \n",
       "16         3                          0  \n",
       "17         3                          0  \n",
       "18         3                          0  \n",
       "19         3                          0  \n",
       "20         3                          0  \n",
       "21         3                          0  \n",
       "22         3                          0  \n",
       "23         3                          0  \n",
       "24         3                          0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c02c085",
   "metadata": {},
   "source": [
    "So simhash finds identical docs perfectly. There were also no false positives, even for a distance threshold, k, of 3.  This suggests that it works better with longer texts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e0029d",
   "metadata": {},
   "source": [
    "# Applying to Blackwing Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2b8f4cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "blackwing_data = pd.read_csv('blackwing_3m_9k.csv')\n",
    "blackwing_data = blackwing_data[blackwing_data['disposition'].isin(['SELECT', 'IGNORE'])]\n",
    "\n",
    "blackwing_data_dict = blackwing_data.text.to_dict()\n",
    "\n",
    "# hash the documents\n",
    "blackwing_objs = [(str(k), Simhash(get_features(v))) for k, v in blackwing_data_dict.items()]\n",
    "\n",
    "# create an index for efficient searching\n",
    "distance_threshold = 1  # hashes > this value will not be considered similar, value must be an integer\n",
    "index = SimhashIndex(blackwing_objs, k=distance_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "a876d396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine how many clusters there are and which docs belong to each cluster\n",
    "clusters = {}\n",
    "cluster_id = 0\n",
    "for simhash_key, hashes in index.bucket.items():\n",
    "    similar_doc_ids = [int(hash_details.split(\",\")[1]) for hash_details in hashes]\n",
    "    clusters[cluster_id] = set(similar_doc_ids)\n",
    "    cluster_id += 1\n",
    "\n",
    "# create a list of tuples representing the edges in a graph\n",
    "edges = set([(x, y) for c in clusters.values() for x, y in combinations_with_replacement(c, 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9533fd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an adjency matrix from the edge list\n",
    "matrix_shape = (len(blackwing_data), len(blackwing_data))  # will be a square adjacency matrix\n",
    "rows, cols = zip(*edges)\n",
    "sparse_mat = coo_matrix((np.ones(len(edges)), (rows, cols)), shape=matrix_shape)\n",
    "\n",
    "# get the cluster for each document\n",
    "nbr_clusters, cluster = connected_components(sparse_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f5031756",
   "metadata": {},
   "outputs": [],
   "source": [
    "blackwing_data['cluster'] = cluster\n",
    "blackwing_data.reset_index(drop=False, inplace=True)\n",
    "blackwing_data.sort_values(by=['cluster', 'index']).reset_index(drop=True).to_csv('blackwing_sorted_by_sim.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844fe7a6",
   "metadata": {},
   "source": [
    "Here is proof that syndicated content is captured..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "76185040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_name</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2229</th>\n",
       "      <td>Anchorage (AK) Daily News</td>\n",
       "      <td>Boosters wane in effectiveness after 4 months ...</td>\n",
       "      <td>Booster shots of the Pfizer-BioNTech and Moder...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2484</th>\n",
       "      <td>Guam Daily Post</td>\n",
       "      <td>Booster effectiveness wanes after 4 months, bu...</td>\n",
       "      <td>Booster shots of the Pfizer-BioNTech and Moder...</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2571</th>\n",
       "      <td>New Delhi (IND) Pioneer</td>\n",
       "      <td>Mcap of nine of top-10 cos erodes by over Rs 1...</td>\n",
       "      <td>Nine of the 10 most valued companies together ...</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>Hindu Business Line (IND)</td>\n",
       "      <td>Mcap of nine of top-10 cos erodes by over Rs 1...</td>\n",
       "      <td>Nine of the 10 most valued companies together ...</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2728</th>\n",
       "      <td>Newshub (NZL)</td>\n",
       "      <td>Climate Change Minister James Shaw was warned ...</td>\n",
       "      <td>Treasury warned even a less ambitious goal wou...</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2762</th>\n",
       "      <td>Outlook India</td>\n",
       "      <td>Mcap Of Nine Most-Valued Firm Declines By Over...</td>\n",
       "      <td>Nine of the 10 most valued companies together ...</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2866</th>\n",
       "      <td>theoutreach.in</td>\n",
       "      <td>Mcap of nine of top-10 cos erodes by over Rs 1...</td>\n",
       "      <td>Nine of the 10 most valued companies together ...</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3005</th>\n",
       "      <td>MSN (NZL)</td>\n",
       "      <td>Climate Change Minister James Shaw was warned ...</td>\n",
       "      <td>Newshub can reveal the Climate Change Minister...</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3123</th>\n",
       "      <td>Gulf Digital News (BHR)</td>\n",
       "      <td>MEBAA Show for business aviation returns in De...</td>\n",
       "      <td>The MEBAA Show the Middle East?s leading busin...</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3145</th>\n",
       "      <td>Travel &amp; Tourism News Middle East</td>\n",
       "      <td>MEBAA Show for business aviation returns in De...</td>\n",
       "      <td>The MEBAA Show the Middle East?s leading busin...</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3171</th>\n",
       "      <td>Trade Arabia (BHR)</td>\n",
       "      <td>MEBAA Show for business aviation returns in De...</td>\n",
       "      <td>The MEBAA Show the Middle East?s leading busin...</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3199</th>\n",
       "      <td>arabianbusinesscommunity.com</td>\n",
       "      <td>Arabian Business Community (ABC), The Region’s...</td>\n",
       "      <td>Looking for products and Services in the Arabi...</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3649</th>\n",
       "      <td>AllAfrica</td>\n",
       "      <td>Botswana Waives Covid-19 Test for Fully Vaccin...</td>\n",
       "      <td>Botswana health authorities say starting Monda...</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3673</th>\n",
       "      <td>vnexplorer.net</td>\n",
       "      <td>Jafza’s Dh13.5 billion food valley set to attr...</td>\n",
       "      <td>? Provided by Khaleej Times Jafza?s integrated...</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3684</th>\n",
       "      <td>Khaleej Times (ARE)</td>\n",
       "      <td>Jafza’s Dh13.5 billion food valley set to attr...</td>\n",
       "      <td>Home/ BusinessJafza?s Dh13.5 billion food vall...</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4082</th>\n",
       "      <td>Afrol News</td>\n",
       "      <td>Botswana Waives Covid-19 Test for Fully Vaccin...</td>\n",
       "      <td>Botswana health authorities say starting Monda...</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4115</th>\n",
       "      <td>ARN (AUS)</td>\n",
       "      <td>Inside the HP-Autonomy lawsuit: Timeline of an...</td>\n",
       "      <td>When Hewlett Packard acquired knowledge manage...</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4170</th>\n",
       "      <td>Reseller News (NZL)</td>\n",
       "      <td>Inside the HP-Autonomy lawsuit: Timeline of an...</td>\n",
       "      <td>When Hewlett Packard acquired knowledge manage...</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4730</th>\n",
       "      <td>Honolulu Civil Beat (HI)</td>\n",
       "      <td>Red Hill’s Firefighting System Was Damaged Lon...</td>\n",
       "      <td>As the public waits for the results of the Nav...</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5131</th>\n",
       "      <td>Yahoo! (UK)</td>\n",
       "      <td>How ‘forever chemicals’ are using marine life ...</td>\n",
       "      <td>First it was PCBs now it?s PFAS ? harmful toxi...</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5143</th>\n",
       "      <td>MSN</td>\n",
       "      <td>How ‘forever chemicals’ are using marine life ...</td>\n",
       "      <td>When scientists found women in the remote Faro...</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5397</th>\n",
       "      <td>My Mother Lode (CA)</td>\n",
       "      <td>Tetra Tech's Bill Bratt Discusses Developing E...</td>\n",
       "      <td>Providing industrial clients with cost-effecti...</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5414</th>\n",
       "      <td>National Law Review</td>\n",
       "      <td>EPA Updates Resources to Help Federal Purchase...</td>\n",
       "      <td>Article ByThe U.S. Environmental Protection Ag...</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6124</th>\n",
       "      <td>Ossining (NY) Patch</td>\n",
       "      <td>Red Hill's Firefighting System Was Damaged Lon...</td>\n",
       "      <td>The system would deploy water automatically in...</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6342</th>\n",
       "      <td>Malvern (AR) Daily Record</td>\n",
       "      <td>Tetra Tech's Bill Bratt Discusses Developing E...</td>\n",
       "      <td>Providing industrial clients with cost-effecti...</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            source_name  \\\n",
       "2229          Anchorage (AK) Daily News   \n",
       "2484                    Guam Daily Post   \n",
       "2571            New Delhi (IND) Pioneer   \n",
       "2644          Hindu Business Line (IND)   \n",
       "2728                      Newshub (NZL)   \n",
       "2762                      Outlook India   \n",
       "2866                     theoutreach.in   \n",
       "3005                          MSN (NZL)   \n",
       "3123            Gulf Digital News (BHR)   \n",
       "3145  Travel & Tourism News Middle East   \n",
       "3171                 Trade Arabia (BHR)   \n",
       "3199       arabianbusinesscommunity.com   \n",
       "3649                          AllAfrica   \n",
       "3673                     vnexplorer.net   \n",
       "3684                Khaleej Times (ARE)   \n",
       "4082                         Afrol News   \n",
       "4115                          ARN (AUS)   \n",
       "4170                Reseller News (NZL)   \n",
       "4730           Honolulu Civil Beat (HI)   \n",
       "5131                        Yahoo! (UK)   \n",
       "5143                                MSN   \n",
       "5397                My Mother Lode (CA)   \n",
       "5414                National Law Review   \n",
       "6124                Ossining (NY) Patch   \n",
       "6342          Malvern (AR) Daily Record   \n",
       "\n",
       "                                               headline  \\\n",
       "2229  Boosters wane in effectiveness after 4 months ...   \n",
       "2484  Booster effectiveness wanes after 4 months, bu...   \n",
       "2571  Mcap of nine of top-10 cos erodes by over Rs 1...   \n",
       "2644  Mcap of nine of top-10 cos erodes by over Rs 1...   \n",
       "2728  Climate Change Minister James Shaw was warned ...   \n",
       "2762  Mcap Of Nine Most-Valued Firm Declines By Over...   \n",
       "2866  Mcap of nine of top-10 cos erodes by over Rs 1...   \n",
       "3005  Climate Change Minister James Shaw was warned ...   \n",
       "3123  MEBAA Show for business aviation returns in De...   \n",
       "3145  MEBAA Show for business aviation returns in De...   \n",
       "3171  MEBAA Show for business aviation returns in De...   \n",
       "3199  Arabian Business Community (ABC), The Region’s...   \n",
       "3649  Botswana Waives Covid-19 Test for Fully Vaccin...   \n",
       "3673  Jafza’s Dh13.5 billion food valley set to attr...   \n",
       "3684  Jafza’s Dh13.5 billion food valley set to attr...   \n",
       "4082  Botswana Waives Covid-19 Test for Fully Vaccin...   \n",
       "4115  Inside the HP-Autonomy lawsuit: Timeline of an...   \n",
       "4170  Inside the HP-Autonomy lawsuit: Timeline of an...   \n",
       "4730  Red Hill’s Firefighting System Was Damaged Lon...   \n",
       "5131  How ‘forever chemicals’ are using marine life ...   \n",
       "5143  How ‘forever chemicals’ are using marine life ...   \n",
       "5397  Tetra Tech's Bill Bratt Discusses Developing E...   \n",
       "5414  EPA Updates Resources to Help Federal Purchase...   \n",
       "6124  Red Hill's Firefighting System Was Damaged Lon...   \n",
       "6342  Tetra Tech's Bill Bratt Discusses Developing E...   \n",
       "\n",
       "                                                   text  cluster  \n",
       "2229  Booster shots of the Pfizer-BioNTech and Moder...       31  \n",
       "2484  Booster shots of the Pfizer-BioNTech and Moder...       31  \n",
       "2571  Nine of the 10 most valued companies together ...       51  \n",
       "2644  Nine of the 10 most valued companies together ...       55  \n",
       "2728  Treasury warned even a less ambitious goal wou...       59  \n",
       "2762  Nine of the 10 most valued companies together ...       51  \n",
       "2866  Nine of the 10 most valued companies together ...       55  \n",
       "3005  Newshub can reveal the Climate Change Minister...       59  \n",
       "3123  The MEBAA Show the Middle East?s leading busin...       83  \n",
       "3145  The MEBAA Show the Middle East?s leading busin...       83  \n",
       "3171  The MEBAA Show the Middle East?s leading busin...       83  \n",
       "3199  Looking for products and Services in the Arabi...       83  \n",
       "3649  Botswana health authorities say starting Monda...      101  \n",
       "3673  ? Provided by Khaleej Times Jafza?s integrated...      103  \n",
       "3684  Home/ BusinessJafza?s Dh13.5 billion food vall...      103  \n",
       "4082  Botswana health authorities say starting Monda...      101  \n",
       "4115  When Hewlett Packard acquired knowledge manage...      115  \n",
       "4170  When Hewlett Packard acquired knowledge manage...      115  \n",
       "4730  As the public waits for the results of the Nav...      138  \n",
       "5131  First it was PCBs now it?s PFAS ? harmful toxi...      150  \n",
       "5143  When scientists found women in the remote Faro...      150  \n",
       "5397  Providing industrial clients with cost-effecti...      160  \n",
       "5414  Article ByThe U.S. Environmental Protection Ag...      162  \n",
       "6124  The system would deploy water automatically in...      138  \n",
       "6342  Providing industrial clients with cost-effecti...      160  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blackwing_data.loc[\n",
    "    blackwing_data.cluster.isin(\n",
    "        blackwing_data.groupby(['cluster'])['source_name'].nunique()[\n",
    "            blackwing_data.groupby(['cluster'])['source_name'].nunique()>1\n",
    "        ].index\n",
    "    ),\n",
    "    ['source_name', 'headline', 'text', 'cluster']\n",
    "].drop_duplicates().head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685d543e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
